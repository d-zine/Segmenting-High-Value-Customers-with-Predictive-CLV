{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761b68e4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2213f",
   "metadata": {},
   "source": [
    "### Utilizes Train Test Split, KFold CV=5, shuffle=True, and RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25d1f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "imputed_data = pd.read_csv(\"sbux_clv_drop_AOV_and_completed_offers_across_channels_with_dummies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64cb7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data=imputed_data.drop(['Unnamed: 0'],axis=1)\n",
    "imputed_data.head()\n",
    "# Log transform \"Sum of Trans. from Day 1-15\"\n",
    "imputed_data['Monetary Value (Sum of Trans. from Day 1-15)'] = np.log(imputed_data['Monetary Value (Sum of Trans. from Day 1-15)'])\n",
    "\n",
    "# Log transform \"Sum(Trans. Amt from Day 16-30)\"\n",
    "imputed_data['Sum(Trans. Amt from Day 16-30)'] = np.log(imputed_data['Sum(Trans. Amt from Day 16-30)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c606aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001  # Define your threshold value here\n",
    "\n",
    "# Filter and drop rows with values close to zero or negative in \"Sum of Trans. from Day 1-15\" column\n",
    "imputed_data = imputed_data[imputed_data['Monetary Value (Sum of Trans. from Day 1-15)'] > threshold]\n",
    "\n",
    "# Filter and drop rows with values close to zero or negative in \"Sum(Trans. Amt from Day 16-30)\" column\n",
    "imputed_data = imputed_data[imputed_data['Sum(Trans. Amt from Day 16-30)'] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9375d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = pd.get_dummies(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a725a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\n",
      "{'num_leaves': 63, 'n_estimators': 500, 'max_depth': -1, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# After calling get dummies in the preprocessing phase,\n",
    "# Drop Gender_Unknown, Age_Unknown, HH Income_Unknown to reduce multicollinearity\n",
    "# Prepare the data\n",
    "X = imputed_data[['MemberSince',\n",
    "                  'Recency (# Days ago from last trans. As of final day up to Day 15)',\n",
    "                  'Frequency (# Trans. from Day 1-15)',\n",
    "                  'Monetary Value (Sum of Trans. from Day 1-15)',\n",
    "                  '# of Marketing offers that Starbucks sent to each customer from Day 1-15',\n",
    "                  '# of Marketing offers that were viewed from Day 1-15',\n",
    "                  '# of Marketing offers that were successfully completed from Day 1-15',\n",
    "                  'Marketing Offer View Rate from Day 1-15',\n",
    "                  'Marketing Offer Response Rate from Day 1-15',\n",
    "                  'Age_18-34', 'Age_35-50', 'Age_51-67',\n",
    "                  'Age_68-84', 'Age_85-101', 'Gender_F', 'Gender_M',  # 'Age_Unknown',\n",
    "                  'Gender_O', 'HH Income_100k-120k',  # 'Gender_Unknown','HH Income_Unknown'\n",
    "                  'HH Income_30k-50k', 'HH Income_50k-75k', 'HH Income_75k-100k']]\n",
    "\n",
    "y = imputed_data['Sum(Trans. Amt from Day 16-30)']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, -1],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning using randomized search and cross-validation\n",
    "model = LGBMRegressor()\n",
    "random_search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=KFold(n_splits=5, shuffle=True),\n",
    "                                   scoring='neg_mean_absolute_error')\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Model Parameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddc1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quantiles\n",
    "quantiles = [0.2, 0.4, 0.6, 0.8, 0.9, 0.95, 0.99]\n",
    "\n",
    "# Calculate actual and predicted CLV quantiles on the test set\n",
    "actual_clv_quantiles = np.quantile(y_test, quantiles)\n",
    "predicted_clv_quantiles = np.quantile(best_model.predict(X_test), quantiles)\n",
    "\n",
    "actual_clv_quantiles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab47166",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_clv_quantiles = [10.81,26.00, 54.95, 99.23, 135.07, 169.55,435.80]\n",
    "predicted_clv_quantiles = np.exp(predicted_clv_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3399b503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.20503663,  30.78521506,  62.64078759,  85.54311423,\n",
       "        94.59935125,  99.94300934, 110.88686861])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_clv_quantiles\n",
    "predicted_clv_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c150fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.20503663,  30.78521506,  62.64078759,  85.54311423,\n",
       "        94.59935125,  99.94300934, 110.88686861])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the results\n",
    "results = pd.DataFrame({\n",
    "    'Quantile': ['Bottom 20%', '20-40%', '40-60%', '60-80%', '80-90%', '90-95%', '95-99%'],\n",
    "    'Avg. Actual CLV': actual_clv_quantiles,\n",
    "    'Avg. Predicted CLV': predicted_clv_quantiles.round(2)\n",
    "})\n",
    "predicted_clv_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0239589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantile</th>\n",
       "      <th>Avg. Actual CLV</th>\n",
       "      <th>Avg. Predicted CLV</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bottom 20%</td>\n",
       "      <td>10.81</td>\n",
       "      <td>11.21</td>\n",
       "      <td>16.94</td>\n",
       "      <td>88.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-40%</td>\n",
       "      <td>26.00</td>\n",
       "      <td>30.79</td>\n",
       "      <td>22.33</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40-60%</td>\n",
       "      <td>54.95</td>\n",
       "      <td>62.64</td>\n",
       "      <td>20.89</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60-80%</td>\n",
       "      <td>99.23</td>\n",
       "      <td>85.54</td>\n",
       "      <td>41.41</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80-90%</td>\n",
       "      <td>135.07</td>\n",
       "      <td>94.60</td>\n",
       "      <td>74.27</td>\n",
       "      <td>47.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90-95%</td>\n",
       "      <td>169.55</td>\n",
       "      <td>99.94</td>\n",
       "      <td>151.27</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95-99%</td>\n",
       "      <td>435.80</td>\n",
       "      <td>110.89</td>\n",
       "      <td>657.88</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quantile  Avg. Actual CLV  Avg. Predicted CLV     MAE  MAPE\n",
       "0  Bottom 20%            10.81               11.21   16.94  88.6\n",
       "1      20-40%            26.00               30.79   22.33  55.5\n",
       "2      40-60%            54.95               62.64   20.89  26.8\n",
       "3      60-80%            99.23               85.54   41.41  34.0\n",
       "4      80-90%           135.07               94.60   74.27  47.1\n",
       "5      90-95%           169.55               99.94  151.27  62.0\n",
       "6      95-99%           435.80              110.89  657.88  88.9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate quantiles\n",
    "quantiles = [0.2, 0.4, 0.6, 0.8, 0.9, 0.95, 0.99]\n",
    "quantile_labels = ['Bottom 20%', '20-40%', '40-60%', '60-80%', '80-90%', '90-95%', '95-99%']\n",
    "\n",
    "# Create a DataFrame to store MAE and MAPE by record in each quantile\n",
    "clv_by_quantile = pd.DataFrame(columns=['Quantile', 'MAE', 'MAPE'])\n",
    "\n",
    "# Iterate over each quantile\n",
    "for i in range(len(quantiles)):\n",
    "    # Select the data points within the quantile range\n",
    "    if i == len(quantiles) - 1:\n",
    "        quantile_mask = (y_test >= np.quantile(y_test, quantiles[i]))\n",
    "    else:\n",
    "        quantile_mask = (y_test >= np.quantile(y_test, quantiles[i])) & (y_test <= np.quantile(y_test, quantiles[i + 1]))\n",
    "    quantile_X = X_test[quantile_mask]\n",
    "    quantile_y = y_test[quantile_mask]\n",
    "    quantile_pred = best_model.predict(quantile_X)\n",
    "\n",
    "    # Ensure quantile_y and quantile_pred have the same length\n",
    "    min_len = min(len(quantile_y), len(quantile_pred))\n",
    "    quantile_y = quantile_y[:min_len]\n",
    "    quantile_pred = quantile_pred[:min_len]\n",
    "\n",
    "    # Convert actual and predicted CLV from logged scale to original scale\n",
    "    quantile_y = np.exp(quantile_y)\n",
    "    quantile_pred = np.exp(quantile_pred)\n",
    "\n",
    "    # Calculate MAE and MAPE for each record\n",
    "    mae = abs(quantile_y - quantile_pred)\n",
    "    mape = abs((quantile_y - quantile_pred) / quantile_y) * 100\n",
    "\n",
    "    # Create a DataFrame for the quantile records\n",
    "    quantile_df = pd.DataFrame({\n",
    "        'Quantile': [quantile_labels[i]] * min_len,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    })\n",
    "\n",
    "    # Append the quantile DataFrame to the overall CLV by quantile DataFrame\n",
    "    clv_by_quantile = clv_by_quantile.append(quantile_df, ignore_index=True)\n",
    "\n",
    "# Calculate the average for each quantile\n",
    "average_by_quantile = clv_by_quantile.groupby('Quantile').mean()\n",
    "\n",
    "# Round MAE to two decimal places and MAPE to one decimal place\n",
    "average_by_quantile['MAE'] = average_by_quantile['MAE'].round(2)\n",
    "average_by_quantile['MAPE'] = average_by_quantile['MAPE'].round(1)\n",
    "\n",
    "# Sort quantiles based on MAE in ascending order, with 'Bottom 20%' first\n",
    "average_by_quantile = average_by_quantile.reindex(index=['Bottom 20%', '20-40%', '40-60%', '60-80%', '80-90%', '90-95%', '95-99%'])\n",
    "\n",
    "# Join the results DataFrame and average by quantile DataFrame on 'Quantile' column\n",
    "joined_df = pd.merge(results, average_by_quantile, on='Quantile')\n",
    "\n",
    "# Display the joined DataFrame\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b29eae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantile</th>\n",
       "      <th>Avg. Actual CLV</th>\n",
       "      <th>Avg. Predicted CLV</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bottom 20%</td>\n",
       "      <td>$10.81</td>\n",
       "      <td>$11.21</td>\n",
       "      <td>16.94</td>\n",
       "      <td>88.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-40%</td>\n",
       "      <td>$26.00</td>\n",
       "      <td>$30.79</td>\n",
       "      <td>22.33</td>\n",
       "      <td>55.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40-60%</td>\n",
       "      <td>$54.95</td>\n",
       "      <td>$62.64</td>\n",
       "      <td>20.89</td>\n",
       "      <td>26.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60-80%</td>\n",
       "      <td>$99.23</td>\n",
       "      <td>$85.54</td>\n",
       "      <td>41.41</td>\n",
       "      <td>34.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80-90%</td>\n",
       "      <td>$135.07</td>\n",
       "      <td>$94.60</td>\n",
       "      <td>74.27</td>\n",
       "      <td>47.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90-95%</td>\n",
       "      <td>$169.55</td>\n",
       "      <td>$99.94</td>\n",
       "      <td>151.27</td>\n",
       "      <td>62.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95-99%</td>\n",
       "      <td>$435.80</td>\n",
       "      <td>$110.89</td>\n",
       "      <td>657.88</td>\n",
       "      <td>88.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quantile Avg. Actual CLV Avg. Predicted CLV     MAE   MAPE\n",
       "0  Bottom 20%          $10.81             $11.21   16.94  88.6%\n",
       "1      20-40%          $26.00             $30.79   22.33  55.5%\n",
       "2      40-60%          $54.95             $62.64   20.89  26.8%\n",
       "3      60-80%          $99.23             $85.54   41.41  34.0%\n",
       "4      80-90%         $135.07             $94.60   74.27  47.1%\n",
       "5      90-95%         $169.55             $99.94  151.27  62.0%\n",
       "6      95-99%         $435.80            $110.89  657.88  88.9%"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round MAE to two decimal places and MAPE to one decimal place\n",
    "average_by_quantile['MAE'] = average_by_quantile['MAE'].round(2).apply(lambda x: '{:,.2f}'.format(x))\n",
    "average_by_quantile['MAPE'] = average_by_quantile['MAPE'].round(1).apply(lambda x: '{:.1f}%'.format(x))\n",
    "\n",
    "# Sort quantiles based on MAE in ascending order, with 'Bottom 20%' first\n",
    "average_by_quantile = average_by_quantile.reindex(index=['Bottom 20%', '20-40%', '40-60%', '60-80%', '80-90%', '90-95%', '95-99%'])\n",
    "\n",
    "# Join the results DataFrame and average by quantile DataFrame on 'Quantile' column\n",
    "joined_df = pd.merge(results, average_by_quantile, on='Quantile')\n",
    "\n",
    "# Add dollar sign to Avg. Actual CLV and Avg. Predicted CLV columns\n",
    "joined_df['Avg. Actual CLV'] = joined_df['Avg. Actual CLV'].apply(lambda x: '${:,.2f}'.format(x))\n",
    "joined_df['Avg. Predicted CLV'] = joined_df['Avg. Predicted CLV'].apply(lambda x: '${:,.2f}'.format(x))\n",
    "\n",
    "# Display the modified joined DataFrame\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89be819",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
